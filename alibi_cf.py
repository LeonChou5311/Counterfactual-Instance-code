# -*- coding: utf-8 -*-
"""Alibi_cf

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Xlcj0--az3yGe5rBKl0woS0i8CiJbLWa
"""

############# Initialise on Google Colab 
from google.colab import drive
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials 
drive.mount('/content/gdrive', force_remount=True)
auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
gdrive = GoogleDrive(gauth)
gdrive.CreateFile({"id": "1wwSN3AIl_dmayKENu5jnc1BRaNPe8BZc"}).GetContentFile("learning.py")



#### Installing Deps ####
!pip3 install pyAgrum
!pip3 install alibi
#### Removing str encoding error ####
# !python3 -m pip install 'h5py==2.10.0' --force-reinstall

# Commented out IPython magic to ensure Python compatibility.
import os

import tensorflow as tf
tf.get_logger().setLevel(40) # suppress deprecation messages
tf.compat.v1.disable_v2_behavior() # disable TF2 behaviour as alibi code still relies on TF1 constructs

### Alibi lib.
from alibi.explainers import CounterFactualProto, CounterFactual

import numpy as np
import pandas as pd

from learning import *
from time import time

### Plotting
import matplotlib
import matplotlib.pyplot as plt
from IPython.display import display
from enum import Enum
# %matplotlib inline

print('TF version: ', tf.__version__)
print('Eager execution enabled (DiCE should be True, Alibi should be False): ', tf.executing_eagerly()) # False
seed = 123
tf.random.set_seed(seed)
np.random.seed(seed)

"""## Retrieve data"""

data=pd.read_csv('gdrive/My Drive//Counterfactual-prototype-main/datasets/diabetes.csv')

# Giving current root path
PATH = "gdrive/My Drive//Counterfactual-prototype-main/"

# name of dataset
DATASET_NAME = "diabetes.csv"

# variable containing the class labels in this case the dataset contains:
# 0 - if not diabetes
# 1 - if diabetes
class_var = "Outcome"

# load dataset
dataset_path = PATH + "datasets/" + DATASET_NAME
data = pd.read_csv( dataset_path )

# features
feature_names = data.drop([class_var], axis=1).columns.to_list()

# balance dataset
sampled_data = data.sample(frac=1)
sampled_data = sampled_data[ sampled_data["Outcome"] == 0]

no_data = sampled_data.sample(frac=1)[0:268]
yes_data = data[ data["Outcome"] == 1]

balanced_data = [no_data,yes_data]
balanced_data = pd.concat(balanced_data)

# apply one hot encoder to data
# standardize the input between 0 and 1
X, Y, encoder, scaler = encode_data( balanced_data, class_var)

n_features = X.shape[1]
n_classes = len(data[class_var].unique())

# load existing training data
print("Loading training data...")
X_train, Y_train, X_test, Y_test, X_validation, Y_validation= load_training_data( dataset_path )

input_data_shape = np.array([X[0]]).shape

print("====================Features====================")
print(feature_names)
print("================================================")

"""## Load model"""

# the best performing model was obtained with 5 hidden layers with 12 neurons each
model_name = "model_h5_N12"

# specify paths where the blackbox model was saved
path_serialisation_model = PATH + "training/" + DATASET_NAME.replace(".csv", "") + "/model/" 
path_serialisation_histr = PATH + "training/" + DATASET_NAME.replace(".csv", "") + "/history/" 

# load model and model performance history
print("Loading Blackbox model...")
model_history = load_model_history( model_name, path_serialisation_histr )
model = load_model( model_name, path_serialisation_model )

# check modelxw
model.summary()

class PredictionType(Enum):
  TruePositive = "TruePositive"
  TrueNegative = "TrueNegative"
  FalsePositive = "FalsePositive"
  FalseNegative = "FalseNegative"
  
class AllPacks(object):
  '''
  Class for storing cases in different prediction type

  '''
  def __init__(self, true_positives,true_negatives, false_positives, false_negatives):
    # constructor
    self.true_positives = true_positives
    self.true_negatives = true_negatives
    self.false_positives = false_positives
    self.false_negatives = false_negatives
  def __len__(self,):
    return len(self.true_positives)\
    +len(self.true_negatives)\
    +len(self.false_positives)\
    +len(self.false_negatives)
    
  def true_positives_len(self,):
    return len(self.true_positives)

  def get_len(self, p_t):
    if p_t == PredictionType.TruePositive:
      return self.true_positives_len()
    elif p_t == PredictionType.TrueNegative:
      return self.true_negatives_len()
    elif p_t == PredictionType.FalsePositive:
      return self.false_positives_len()
    elif p_t == PredictionType.FalseNegative:
      return self.false_negatives_len()
    else:
      raise NotImplemented('This prediction type is unsupported.');

  def true_negatives_len(self,):
    return len(self.true_negatives)
  
  def false_negatives_len(self,):
    return len(self.false_negatives)
  
  def false_positives_len(self,):
    return len(self.false_positives)

  def get_instance(self, p_t, index):
    if p_t == PredictionType.TruePositive:
      return self.get_true_positive(index)
    elif p_t == PredictionType.TrueNegative:
      return self.get_true_negative(index)
    elif p_t == PredictionType.FalsePositive:
      return self.get_false_positive(index)
    elif p_t == PredictionType.FalseNegative:
      return self.get_false_nagative(index)
    else:
      raise NotImplemented('This prediction type is unsupported.');

  def get_true_positive(self, index = 0):
    try:
      return self.true_positives[index]
    except:
      raise ValueError("Input index out of range, true positive only have [%d] cases" % (self.true_positives_len()))
  def get_true_negative(self, index = 0):
    try:
      return self.true_negatives[index]
    except:
      raise ValueError("Input index out of range, true negative only have [%d] cases" % (self.true_negatives_len()))
  def get_false_positive(self, index = 0):
    try:
      return self.false_positives[index]
    except:
      raise ValueError("Input index out of range, true positive only have [%d] cases" % (self.false_positives_len()))
  def get_false_nagative(self, index = 0):
    try:
      return self.false_negatives[index]
    except:
      raise ValueError("Input index out of range, true positive only have [%d] cases" % (self.false_negatives_len()))

diabetes_feature_range = (X_train.min(axis=0), X_train.max(axis=0))
# store all information 
local_data_dict = generate_local_predictions( X_test, Y_test, model, scaler, encoder )
# sorting by different conditions
true_positives,true_negatives, false_positives, false_negatives = wrap_information( local_data_dict )

all_packs = AllPacks(true_positives,true_negatives, false_positives, false_negatives)

all_packs.get_instance(PredictionType.TruePositive, 0)

##### Utils #####
def print_block(title, content, mark_times=20):
  upper_line = mark_times*("=") + title + mark_times*("=")
  bottom_line = len(upper_line) *"="
  print(upper_line)
  if (type(content) == pd.DataFrame):
    display(content)
  else:
    print("| \t" + str(content))
  print(bottom_line)
  print("\n")

class AlibiCounterfactaulWrapper(object):
  '''
  Wrapper class to generate alibi cf
  '''
  def __init__(self, counterfactual_proto, counterfactual):
    self.counterfactual_proto__ = counterfactual_proto
    self.counterfactual__ = counterfactual
    
  def counterfactual_proto_explain(self, case):
    return self.run_counterfactual_print_result(case, self.counterfactual_proto__)

  def counterfactual_explain(self, case):
    return self.run_counterfactual_print_result(case, self.counterfactual__)
  
  def run_counterfactual_print_result(self, case, cf):
    return_case = deepcopy(case)
    # print_block("", "Finding counterfactuals...")
    input_data = np.array([case["scaled_vector"]])
    start_time = time()
    explanation = cf.explain(input_data)
    end_time = time()
    time_took = end_time - start_time
    # print_block("Time Took", "%.3f sec" % (time_took))
    if explanation.cf == None:
      # print_block("", "No counterfactaul found!")
      return_case['cf'] = [None] * input_data.shape[1]
    else:  
      counterfactual = scaler.inverse_transform(explanation.cf['X'])
      return_case['cf'] = counterfactual.tolist()[0]

    return_case['time'] = time_took
    # self.print_counterfactual_results(case, counterfactual)
    return return_case

  def print_counterfactual_results(self, case, counterfactual):
    print_block("Prediction type", case["prediction_type"], mark_times=7)
    print_block("Black box prediction", case["predictions"], mark_times=3)
    print_block("Ground truth", case["ground_truth"], mark_times= 5)
    print_block("Oringal input", pd.DataFrame([case["original_vector"]], columns=feature_names),mark_times = 60)
    print_block("Counterfactual", pd.DataFrame(counterfactual, columns=feature_names), mark_times=60)

##### Initialise Cfs

cf = CounterFactual(model, input_data_shape, distance_fn='l1', target_proba=1.0,
                    target_class='other', max_iter=3000, early_stop=150, lam_init=1e-1,
                    max_lam_steps=10, tol=0.05, learning_rate_init=0.1,
                    feature_range=diabetes_feature_range, eps=0.01, init='identity',
                    decay=True, write_dir=None, debug=False)

cf_p = CounterFactualProto(model, input_data_shape, use_kdtree=True, theta=10., max_iterations=1000,
                         feature_range=diabetes_feature_range,
                         c_init=1., c_steps=10)

cf_p.fit(X_train)

""

alibi_cf =  AlibiCounterfactaulWrapper(counterfactual_proto= cf_p, counterfactual= cf)

output_column_names= [ f'orgin_{f}' for f in feature_names] + [ f'cf_{f}' for f in feature_names] + ['time(sec)'] + ["prediction_type"]

def generate_df_for_all(packs, cf_func):
  ### Create an empty dataframe for appending data.
  result_df = pd.DataFrame({}, columns= output_column_names)

  ### Loop through each predict type.
  for p_t in [PredictionType.TruePositive, PredictionType.TrueNegative, PredictionType.FalsePositive, PredictionType.FalseNegative]:
    print_block("","Doing %s" % p_t.value)

    ### Get the length, so we can through all the instance in this predict type.
    total_length = packs.get_len(p_t)
    
    ### Loop through all the instance in this predict type.
    for i in range(total_length):

      print_block("Instance %d" %i, "Running...")

      ### Get the result (including counterfactal and running time) from the cf_func.
      returned_case = cf_func(packs.get_instance(p_t, i))

      ### Using the information from returned_case to create a dataframe (for appending to result_df).
      df_i = pd.DataFrame([
      returned_case["original_vector"] + returned_case['cf'] + [returned_case['time'], returned_case['prediction_type']]],columns=output_column_names)

      ### appending the current result to the total result dataframe.
      result_df = result_df.append(df_i)
  return result_df

cf_result_df = generate_df_for_all(all_packs, alibi_cf.counterfactual_explain)

cf_result_df

## save the csv
cf_result_df.to_csv('cf_result_df.csv')

## read the csv
try_load_cf_result_df = pd.read_csv('cf_result_df.csv')

try_load_cf_result_df.head(5)

"""# CF"""

cf_pro_result_df = generate_df_for_all(all_packs, alibi_cf.counterfactual_proto_explain)

## save the csv
cf_pro_result_df.to_csv('cf_pro_result_df.csv')

## read the csv
try_load_cf_result_df = pd.read_csv('cf_pro_result_df.csv')